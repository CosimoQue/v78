---
title: One-Shot Visual Imitation Learning via Meta-Learning
abstract: In order for a robot to be a generalist that can perform a wide range of
  jobs, it must be able to acquire a wide variety of skills quickly and efficiently
  in complex unstructured environments. High-capacity models such as deep neural networks
  can enable a robot to represent complex skills, but learning each skill from scratch
  then becomes infeasible. In this work, we present a meta-imitation learning method
  that enables a robot to learn how to learn more efficiently, allowing it to acquire
  new skills from just a single demonstration. Unlike prior methods for one-shot imitation,
  our method can scale to raw pixel inputs and requires data from significantly fewer
  prior tasks for effective learning of new skills. Our experiments on both simulated
  and real robot platforms demonstrate the ability to learn new tasks, end-to-end,
  from a single visual demonstration.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: finn17a
month: 0
tex_title: One-Shot Visual Imitation Learning via Meta-Learning
firstpage: 357
lastpage: 368
page: 357-368
order: 357
cycles: false
author:
- given: Chelsea
  family: Finn
- given: Tianhe
  family: Yu
- given: Tianhao
  family: Zhang
- given: Pieter
  family: Abbeel
- given: Sergey
  family: Levine
date: 2017-10-18
address: 
publisher: PMLR
container-title: Proceedings of the 1st Annual Conference on Robot Learning
volume: '78'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 10
  - 18
pdf: http://proceedings.mlr.press/v78/finn17a/finn17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
