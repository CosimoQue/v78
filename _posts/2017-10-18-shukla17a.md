---
title: Learning Human Utility from Video Demonstrations for Deductive Planning in
  Robotics
abstract: We uncouple three components of autonomous behavior (utilitarian value,
  causal reasoning, and fine motion control) to design an interpretable model of tasks
  from video demonstrations. Utilitarian value is learned from aggregating human preferences
  to understand the implicit goal of a task, explaining \textitwhy an action sequence
  was performed.  Causal reasoning is seeded from observations and grows from robot
  experiences to explain \textithow to deductively accomplish sub-goals. And lastly,
  fine motion control describes \textitwhat actuators to move. In our experiments,
  a robot learns how to fold t-shirts from visual demonstrations, and proposes a plan
  (by answering \textitwhy, \textithow, and \textitwhat) when folding never-before-seen
  articles of clothing.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: shukla17a
month: 0
tex_title: Learning Human Utility from Video Demonstrations for Deductive Planning
  in Robotics
firstpage: 448
lastpage: 457
page: 448-457
order: 448
cycles: false
author:
- given: Nishant
  family: Shukla
- given: Yunzhong
  family: He
- given: Frank
  family: Chen
- given: Song-Chun
  family: Zhu
date: 2017-10-18
address: 
publisher: PMLR
container-title: Proceedings of the 1st Annual Conference on Robot Learning
volume: '78'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 10
  - 18
pdf: http://proceedings.mlr.press/v78/shukla17a/shukla17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
